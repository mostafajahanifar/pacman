{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "from survival_utils import CoxPH_train_val, CoxPH_train_infer, clinic_eval, extract_train_val_hazard_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18391/919052237.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  features_std = discov_df.std()\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.78s/it]\n"
     ]
    }
   ],
   "source": [
    "plots_save_path = 'all_feats_combi/KM_plots/'\n",
    "##path to the csv file containing features for all the sets/cases including train/val\n",
    "discov_val_feats_path = 'all_feats_combi/features_combined/NOTT/discovery_valid_combined.csv'\n",
    "discov_df = pd.read_csv(discov_val_feats_path)\n",
    "all_feats_list = list(discov_df.columns[39:]) # start from digital features in the matrix\n",
    "\n",
    "# clear the features based on std\n",
    "feats_list = []\n",
    "features_std = discov_df.std()\n",
    "for feat in all_feats_list:\n",
    "    std_value = features_std[feat]\n",
    "    if std_value > 0.5:\n",
    "       feats_list.append(feat) \n",
    "\n",
    "# defining the parameters for survival analysis\n",
    "model_type = 'cox' ## 'rsf': for Random Survival Forest, 'cox': for Cox PH regression model\n",
    "save_plot = True ##whether to save the KM curve plots\n",
    "censor_at = 120 #in months. e.g 10 years = 120 months. 180 for 15 years, 240 for 20 years. Use -1 if no censoring is required \n",
    "rsf_rseed = 100 ## random seed for Random Survival Forest\n",
    "cutoff_mode = 'median' ## 'median' | 'mean' ## the cut off point calculation for stratification of high vs low risk cases\n",
    "cutoff_point =  -1 ## 0.92 ##if set to -1 then median will be used as cut off. If set to any other positive value then cut_mode option will be ignores and the fixed cut off provided will be used for stratification of high vs low risk cases\n",
    "time_col = 'TTDM/ month' #'TTDM/ month' | 'Breast cancer specific survival/ month'\n",
    "event_col = 'Distant Metastasis' #'Distant Metastasis' | 'Survival Status'\n",
    "subset = 'Endocrine_LN0' ##'Endocrine'|'Endocrine_LN0'; 'Endocrine': Endocrine treated only with lymph node 0-3; 'Endocrine_LN0': Endocrine treated lymph node negative\n",
    "\n",
    "######################################### Start the bootstraping\n",
    "# initialize the output lists\n",
    "bootsrap_num = 10\n",
    "hr_scores = pd.DataFrame(1, index=np.arange(bootsrap_num), columns=feats_list)\n",
    "EE = discov_df[event_col].to_numpy()\n",
    "rng = np.random.RandomState()\n",
    "for run in tqdm(range(1)):\n",
    "    index_train = list(rng.choice(np.nonzero(EE==0)[0],size = len(EE)-np.sum(EE),replace=True))+list(rng.choice(np.nonzero(EE==1)[0],size = np.sum(EE),replace=True))\n",
    "    index_test = list(set(range(len(EE))).difference(index_train))\n",
    "    \n",
    "    train_set = discov_df.iloc[index_train]\n",
    "    test_set = discov_df.iloc[index_test]\n",
    "    \n",
    "    train_set.reset_index(inplace=True)\n",
    "    test_set.reset_index(inplace=True)\n",
    "    # tpv, tcind, thz, thz_ci_l, thz_ci_h, vpv, vcind, vhz, vhz_ci_l, vhz_ci_h, cutpnt, hr_scores = CoxPH_train_val(train_set, test_set, plots_save_path, feats_list, time_col, event_col, subset, censor_at, save_plot, cutoff_mode, cutoff_point, hr_scores, 0)\n",
    "    \n",
    "    if run == 0:\n",
    "        test_hazard_ratios, c_index, p_value = extract_train_val_hazard_ratios(train_set, test_set, plots_save_path, feats_list, time_col, event_col, subset, censor_at, save_plot, cutoff_mode, cutoff_point)\n",
    "        \n",
    "        # print(test_hazard_ratios.tolist())\n",
    "        # print(len(test_hazard_ratios.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hazard_ratios = pd.concat([test_hazard_ratios, test_hazard_ratios], axis=1, join='outer', ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9712343863942743"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_std['nodeDegrees_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "covariate\n",
       "g1_g3_ratio_g2                                 1.004749\n",
       "g1_ratio_g2                                    1.000157\n",
       "g1_ratio_g3                                    0.994123\n",
       "g2_g3_ratio_g1                                 0.857903\n",
       "g2_ratio_g3                                    1.000000\n",
       "                                                 ...   \n",
       "ratio_intra_WSI_p1p3_patch_cooccur_low_high    1.006479\n",
       "ratio_intra_WSI_p2p2_patch_cooccur_low_high    0.988744\n",
       "ratio_intra_WSI_p2p3_patch_cooccur_low_high    0.986664\n",
       "ratio_intra_WSI_p3p3_patch_cooccur_low_high    1.027865\n",
       "stromal_contrast                               0.863004\n",
       "Length: 265, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrs_mean = test_hazard_ratios.mean(axis=1)\n",
    "hrs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(train_set, test_set, feats_list):\n",
    "    feat_mean = train_set[feats_list].mean()\n",
    "    feat_std = train_set[feats_list].std()\n",
    "    \n",
    "    train_set_normalized = train_set.copy()\n",
    "    test_set_normalized = test_set.copy()\n",
    "    train_set_normalized[feats_list] =( train_set[feats_list] - feat_mean ) / feat_std\n",
    "    test_set_normalized[feats_list] =( test_set[feats_list] - feat_mean ) / feat_std\n",
    "    \n",
    "    return train_set_normalized, test_set_normalized\n",
    "\n",
    "train_set_n1, test_set_n1 = normalize_df(train_set, test_set, feats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12047/2133161088.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set[feat] =( test_set[feat] - feat_mean ) / feat_std\n"
     ]
    }
   ],
   "source": [
    "def normalize_df_2(train_set, test_set, feats_list):\n",
    "    for feat in feats_list:\n",
    "        feat_mean = train_set[feat].mean()\n",
    "        feat_std = train_set[feat].std()\n",
    "    \n",
    "        train_set[feat] =( train_set[feat] - feat_mean ) / feat_std\n",
    "        test_set[feat] =( test_set[feat] - feat_mean ) / feat_std\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "train_set_n2, test_set_n2 = normalize_df_2(train_set, test_set, feats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train_set_n2.equals(train_set_n1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "437ec96c40eefae2cb702735df791d1b7540f37193e191477298877c442313ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
